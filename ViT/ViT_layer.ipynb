{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/google-research/vision_transformer [참고]\n",
    "\n",
    "transformer encoder를 적게 사용하여 transformer encoder의 성능과 효과를 알아보자\n",
    "\n",
    " Vision Transformer의 동작 과정.\n",
    "1. 입력된 이미지를 patch + position embedding을 한다.\n",
    "2. embedding된 이미지 패치를 transformer encoder로 넣는다.\n",
    "3. transformer encoder에 의해 encoding된 정보가 나온다.\n",
    "4. MLP를 이용하여 출력 dimension을 조정 한다.\n",
    "\n",
    "embedding시 dimension과 encoding시 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.Module vs tf.keras.layers.Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 파이썬의 클래스, 상속/ 데코레이터 공부 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/intro_to_modules 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.Module):\n",
    "    def __init__(self, in_features, out_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.w = tf.Variable(\n",
    "            tf.random.normal([in_features, out_features]),\n",
    "            name='w'\n",
    "        )\n",
    "        self.b = tf.Variable(\n",
    "            tf.zeros([out_features]),\n",
    "            name='b'\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        print(x.shape, self.w.shape, self.b.shape)\n",
    "        y = tf.matmul(x, self.w) + self.b\n",
    "        return tf.nn.relu(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3) (3, 2) (2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.8601856, 4.9089665]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = Dense(in_features=3,out_features=2,name='test')\n",
    "dense(tf.constant([[2.0,2.0,2.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 17:24:13.330726: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[-0.7431357 ,  1.3614383 ],\n",
       "        [-0.00665876,  0.9016345 ],\n",
       "        [ 1.1798873 ,  0.19141059]], dtype=float32)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Module을 사용하여 위와 같이 custom layer를 생성하면,\n",
    "tf.Variable 또는 할당된 tf.Module 인스턴스를 재귀적으로 자동으로 수집한다. \n",
    "수집된 값은 (tf.Module).submodules나 (tf.Module).variables로 확인이 가능하다.\n",
    "자동으로 수집된 값을 통해 단일 모델 인스턴스로 tf.Module 모음을 관리하고 전체 모델을 저장 및 로드할 수 있다.\n",
    "\n",
    "하지만 init에서 변수의 크기를 지정하기 때문에 입출력의 길이가 정해진 상황에서만 사용할수 있다는 단점이 있다.\n",
    "변수 생성을 연기함으로써 입력크기를 미리 지정하지 않아도 되도록 해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleDense(tf.Module):\n",
    "    def __init__(self, out_features, name=None): # in_features를 고정하지 않음으로써 입력의 크기에 따라 변화 가능\n",
    "        super().__init__(name=name)\n",
    "        self.is_built = False\n",
    "        self.out_features = out_features\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if not self.is_built: # call 할때마다 변수를 새로 만들면 안된다. 학습이 불가능해 질 것.\n",
    "            self.w = tf.Variable(\n",
    "                tf.random.normal([x.shape[-1], self.out_features]),\n",
    "                name='w'\n",
    "            )\n",
    "            self.b = tf.Variable(\n",
    "                tf.zeros([self.out_features]),\n",
    "                name='b'\n",
    "            )\n",
    "            self.is_built = True\n",
    "\n",
    "        y = tf.matmul(x,self.w)+self.b\n",
    "        return tf.nn.relu(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 가중치를 저장할 수 있다고 했는데 tf.train.Checkpoint를 이용하거나 tf.saved_model.save를 이용하면 된다.\n",
    "여기서는 자세히 다루지 않으니 관심이 있다면 원문을 참고하거나 tensorflow document를 참고하자.\n",
    "\n",
    "tensorflow는 original code없이 실행할 수 있는데, 이를 위해서는 코드를 그래프를 만들어야 한다.\n",
    "TensorFlow needs to know how to do the computations described in Python, but without the original code.\n",
    "해당 코드가 그래프로 실행되어야 함을 나타내기 위해서는 @tf.function 데코레이터를 사용하면 되는데\n",
    "자세한 내용은 tensorflow document를 참고하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, in_features, out_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.w = tf.Variable(\n",
    "            tf.random.normal([in_features, out_features]),\n",
    "            name='w'\n",
    "        )\n",
    "        self.b = tf.Variable(\n",
    "            tf.zeros([out_features]),\n",
    "            name='b'\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        y = tf.matmul(x,self.w) + self.b\n",
    "        return tf.nn.relu(y)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.       , 1.7542236]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasDense = KerasDense(in_features=3,out_features=2, name='test')\n",
    "kerasDense(tf.constant([[2.0,2.0,2.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 위와 같은 형태는 앞선 tf.Module의 첫번째 예시와 같이 입력의 형태가 정해졌을 때(미리 알고 있을 때)만 사용가능하다.\n",
    "입력의 형태(shape)에 맞게 w의 형태가 바뀌도록 코드를 수정해보자.\n",
    "\n",
    "tf.keras.layers.Layer에는 build를 이용하여 앞서 말한것과 같은 유연성을 추가 할 수 있다.\n",
    "tf.Module에서 사용한 self.is_built가 필요없고 build는 한번만 호출되며 호출될때 입력 형태가 입력으로 주어진다.\n",
    "일반적으로 변수를 만들때 사용한다.\n",
    "위의 코드를 build를 이용하여 수정해보면 다음과 같다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleKerasDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.out_features=out_features\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(\"호출됨\") # build가 언제 호출되는지 확인하기 위해 -> call하면 먼저 build가 호출됨.\n",
    "        self.w = tf.Variable(\n",
    "            tf.random.normal([input_shape[-1],self.out_features]),\n",
    "            name='w'\n",
    "        )\n",
    "        self.b = tf.Variable(\n",
    "            tf.zeros([self.out_features]),\n",
    "            name='b'\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        y = tf.matmul(x,self.w)+self.b\n",
    "        return tf.nn.relu(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexibleKerasDense = FlexibleKerasDense(out_features=3, name='test')\n",
    "flexibleKerasDense.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아직 build(변수를 생성하기)전 이므로 (tf.keras.layers.Layer).variables로 확인해보면 변수가 없음을 알수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호출됨\n"
     ]
    }
   ],
   "source": [
    "flexibleKerasDense.build(input_shape=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w:0' shape=(3, 3) dtype=float32, numpy=\n",
       " array([[ 1.8093308 ,  1.3985857 , -0.1626937 ],\n",
       "        [ 0.69540864, -2.4313014 , -1.1886083 ],\n",
       "        [-0.6576047 ,  0.08592828, -0.41285878]], dtype=float32)>,\n",
       " <tf.Variable 'b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexibleKerasDense.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build를 통해 변수가 생성되었음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호출됨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[0.       , 6.2020826, 2.8126462]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexibleKerasDense(tf.constant([[2.0,2.0,2.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build는 한번 호출된다고 했는데 한번더 호출하면 어떻게 될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호출됨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w:0' shape=(3, 3) dtype=float32, numpy=\n",
       " array([[ 0.26520932, -1.2972199 ,  0.7670775 ],\n",
       "        [ 0.2215567 , -0.7744951 , -1.1051631 ],\n",
       "        [-0.09190309, -0.56559503, -1.2046446 ]], dtype=float32)>,\n",
       " <tf.Variable 'b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexibleKerasDense.build(input_shape=(1,3))\n",
    "flexibleKerasDense.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "호출됨\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w:0' shape=(4, 3) dtype=float32, numpy=\n",
       " array([[-0.30019194,  1.1981277 , -2.585424  ],\n",
       "        [-0.4498049 ,  1.5245918 ,  0.36952665],\n",
       "        [-0.55717415, -1.2138438 ,  0.37801775],\n",
       "        [-0.13454318,  0.47015575,  0.6181564 ]], dtype=float32)>,\n",
       " <tf.Variable 'b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexibleKerasDense.build(input_shape=(1,4))\n",
    "flexibleKerasDense.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"test\" (type FlexibleKerasDense).\n\nIn[0] and In[1] has different ndims: [3] vs. [4,3] [Op:MatMul]\n\nCall arguments received:\n  • x=tf.Tensor(shape=(3,), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb 셀 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m flexibleKerasDense(tf\u001b[39m.\u001b[39;49mconstant([\u001b[39m2.0\u001b[39;49m,\u001b[39m2.0\u001b[39;49m,\u001b[39m2.0\u001b[39;49m]))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m flexibleKerasDense\u001b[39m.\u001b[39mvariables\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32m/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb 셀 24\u001b[0m in \u001b[0;36mFlexibleKerasDense.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     y \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mmatmul(x,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb#X42sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu(y)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"test\" (type FlexibleKerasDense).\n\nIn[0] and In[1] has different ndims: [3] vs. [4,3] [Op:MatMul]\n\nCall arguments received:\n  • x=tf.Tensor(shape=(3,), dtype=float32)"
     ]
    }
   ],
   "source": [
    "flexibleKerasDense(tf.constant([2.0,2.0,2.0]))\n",
    "flexibleKerasDense.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "빌드를 호출하여 강제로 input_shape에 맞게 조절되도록 하면 변화하지만,<br>\n",
    "빌드된 input_shape과 맞지 않는 형식의 input이 들어오면 입력이 거부된다.<br>\n",
    "\n",
    "\n",
    "tf.keras.layers.Layer에는 다음과 같은 추가 기능이 있다. 참고하자.<br>\n",
    "* Optional losses\n",
    "* Support for metrics\n",
    "* Built-in support for an optional training argument to differentiate between training and inference use\n",
    "* get_config and from_config methods that allow you to accurately store configurations to allow model cloning in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 tf.keras.Model이다.<br>\n",
    "모델을 정의할때 functional 방식이나 sequential 방식을 통해 keras 레이어가 중첩된 상태로 정의할수도 있지만,<br>\n",
    "keras에서 제공하는 모델 클래스도 있다.<br>\n",
    "tf.keras.layers.Laer에서 상속되므로 tf.keras.Model은 tf.keras.layers.Layer에 해당하며 같은 방식으로 사용, 중첩 및 저장할 수 있다.<br>\n",
    "\n",
    "tf.keras.Model에서 tf.Module에서와 같이 체크포인트를 사용할수도 있지만,<br>\n",
    "(tf.keras.Model).save(저장경로)나 (tf.keras.Model).save_weights를 사용할 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### + 케라스 레이어에서 변수의 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.w1 = tf.Variable(\n",
    "        tf.random.normal([3, 4]), \n",
    "        name='w1',\n",
    "        trainable=True)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w2 = tf.Variable(\n",
    "        tf.random.normal([3, 4]), \n",
    "        name='w2',\n",
    "        trainable=True)\n",
    "\n",
    "    def call(self,input):\n",
    "        return input+self.w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = Add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w1:0' shape=(3, 4) dtype=float32, numpy=\n",
       " array([[ 0.01372894,  1.7182862 ,  0.3679221 , -0.02330149],\n",
       "        [ 0.77180237, -0.11622601,  0.97889197,  0.41070986],\n",
       "        [-1.4942025 , -0.41123697,  0.18962502, -0.22718611]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w1:0' shape=(3, 4) dtype=float32, numpy=\n",
       " array([[ 0.01372894,  1.7182862 ,  0.3679221 , -0.02330149],\n",
       "        [ 0.77180237, -0.11622601,  0.97889197,  0.41070986],\n",
       "        [-1.4942025 , -0.41123697,  0.18962502, -0.22718611]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w1:0' shape=(3, 4) dtype=float32, numpy=\n",
       " array([[ 0.01372894,  1.7182862 ,  0.3679221 , -0.02330149],\n",
       "        [ 0.77180237, -0.11622601,  0.97889197,  0.41070986],\n",
       "        [-1.4942025 , -0.41123697,  0.18962502, -0.22718611]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "add.build([1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w1:0' shape=(3, 4) dtype=float32, numpy=\n",
       " array([[ 0.01372894,  1.7182862 ,  0.3679221 , -0.02330149],\n",
       "        [ 0.77180237, -0.11622601,  0.97889197,  0.41070986],\n",
       "        [-1.4942025 , -0.41123697,  0.18962502, -0.22718611]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'w2:0' shape=(3, 4) dtype=float32, numpy=\n",
       " array([[-1.286846  ,  0.27606416, -1.220971  , -0.5353937 ],\n",
       "        [ 0.32372358,  0.11204606,  1.1905655 , -0.52809995],\n",
       "        [ 0.31775156,  1.2310293 , -0.28288323,  0.77270275]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import requests\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = np.array(image)\n",
    "    image_resized = tf.image.resize(image, (32, 32))\n",
    "    image_resized = tf.cast(image_resized, tf.float32)\n",
    "    image_resized = (image_resized - 127.5) / 127.5\n",
    "    return tf.expand_dims(image_resized, 0).numpy()\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    response = requests.get(url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    image = preprocess_image(image)\n",
    "    return image\n",
    "\n",
    "img_url = \"https://p0.pikrepo.com/preview/853/907/close-up-photo-of-gray-elephant.jpg\"\n",
    "image = load_image_from_url(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n",
      "(1, 14, 14, 768)\n"
     ]
    }
   ],
   "source": [
    "print(image.shape)\n",
    "patches = tf.image.extract_patches(\n",
    "    images=image,\n",
    "    sizes=[1,16,16,1],\n",
    "    strides=[1,16,16,1],\n",
    "    rates=[1,1,1,1],\n",
    "    padding='VALID'\n",
    ")\n",
    "print(patches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(tf.keras.layers.Layer):\n",
    "    # batch image to batch image patches\n",
    "    def __init__(self, patch_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size = patch_size # image를 크기가 몇인 정사각형 patch로 쪼개볼까\n",
    "        self.patch_dim = patch_size*patch_size*3\n",
    "\n",
    "    def build(self, input_shape): # (batch, height, width, channel)\n",
    "        # create the state of the layer (weights)\n",
    "        if input_shape[1] % self.patch_size != 0 or input_shape[2] % self.patch_size !=0 :\n",
    "            print(\"이미지의 크기를 설정한 크기로 나눌수 없습니다.\")\n",
    "            print(\"input image shape: {}\".format(input_shape))\n",
    "            print(\"patch size setting: {}\".format(self.patch_size))\n",
    "            raise Exception()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        patches = tf.image.extract_patches(inputs, \n",
    "                    sizes=[1,self.patch_size,self.patch_size,1], \n",
    "                    strides=[1,self.patch_size,self.patch_size,1],\n",
    "                    rates=[1,1,1,1],\n",
    "                    padding='VALID'\n",
    "                )\n",
    "\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       "array([[-0.22769608, -0.2747549 , -0.38455883, -0.5579657 , -0.58933824,\n",
       "        -0.6834559 , -0.68835783, -0.7197304 , -0.8060049 , -0.7278186 ,\n",
       "        -0.751348  , -0.82193625, -0.5688726 , -0.592402  , -0.6629902 ,\n",
       "        -0.5397059 , -0.5632353 , -0.6338235 , -0.41127452, -0.4269608 ,\n",
       "        -0.5446078 , -0.54987746, -0.56556374, -0.6675245 , -0.44080883,\n",
       "        -0.46433824, -0.5349265 , -0.76691175, -0.7982843 , -0.8688725 ,\n",
       "        -0.8039216 , -0.8352941 , -0.92156863, -0.15294118, -0.18431373,\n",
       "        -0.25490198, -0.11360294, -0.13713235, -0.19203432, -0.15821078,\n",
       "        -0.1817402 , -0.23664215, -0.09276961, -0.10061274, -0.13982843,\n",
       "        -0.08762255, -0.07977941, -0.12683824, -0.7420343 , -0.7655637 ,\n",
       "        -0.83615196, -0.92965686, -0.9531863 , -0.9922794 , -0.86531866,\n",
       "        -0.88884807, -0.94375   , -0.5634804 , -0.5870098 , -0.657598  ,\n",
       "        -0.5908088 , -0.6143382 , -0.6692402 , -0.6305147 , -0.6540441 ,\n",
       "        -0.7246324 , -0.36495098, -0.3884804 , -0.5061275 , -0.6093137 ,\n",
       "        -0.6406863 , -0.7269608 , -0.48566177, -0.50919116, -0.5797794 ,\n",
       "        -0.6113971 , -0.66629905, -0.72904414, -0.22965686, -0.2531863 ,\n",
       "        -0.30808824, -0.20759805, -0.20759805, -0.27034312, -0.19975491,\n",
       "        -0.20759805, -0.24681373, -0.16102941, -0.16887255, -0.2002451 ,\n",
       "        -0.23137255, -0.22352941, -0.27058825, -0.23921569, -0.21568628,\n",
       "        -0.27058825, -0.5372549 , -0.6       , -0.7019608 , -0.5833333 ,\n",
       "        -0.6460784 , -0.7480392 , -0.7683824 , -0.7997549 , -0.87034315,\n",
       "        -0.37095588, -0.3944853 , -0.44938725, -0.6925245 , -0.7160539 ,\n",
       "        -0.77095586, -0.56017154, -0.5915441 , -0.6621324 , -0.6693627 ,\n",
       "        -0.685049  , -0.77916664, -0.6965686 , -0.72794116, -0.7985294 ,\n",
       "        -0.75330883, -0.82389706, -0.8944853 , -0.4077206 , -0.46262255,\n",
       "        -0.5253676 , -0.22855392, -0.22071078, -0.28345588, -0.2577206 ,\n",
       "        -0.24987745, -0.31262255, -0.26838234, -0.2605392 , -0.32328433,\n",
       "        -0.3439951 , -0.3439951 , -0.42806372, -0.24142157, -0.21789216,\n",
       "        -0.27279413, -0.2577206 , -0.24987745, -0.29693627, -0.41875   ,\n",
       "        -0.4814951 , -0.5677696 , -0.61629903, -0.6476716 , -0.7339461 ,\n",
       "        -0.94620097, -0.9697304 , -0.9860294 , -0.4742647 , -0.5056372 ,\n",
       "        -0.5762255 , -0.47340685, -0.5047794 , -0.5753676 , -0.46139705,\n",
       "        -0.4927696 , -0.56335783, -0.5595588 , -0.5830882 , -0.65367645,\n",
       "        -0.75919116, -0.8297794 , -0.9003676 , -0.59767157, -0.6322304 ,\n",
       "        -0.66593134, -0.37083334, -0.37083334, -0.43357843, -0.3365196 ,\n",
       "        -0.360049  , -0.43063724, -0.3129902 , -0.3129902 , -0.37573528,\n",
       "        -0.3153186 , -0.29963234, -0.33884802, -0.32230392, -0.2987745 ,\n",
       "        -0.36936274, -0.3310049 , -0.30747548, -0.37806374, -0.2932598 ,\n",
       "        -0.27757353, -0.3167892 , -0.60723037, -0.6621324 , -0.74056375,\n",
       "        -0.5167892 , -0.5403186 , -0.59522057, -0.71004903, -0.7417892 ,\n",
       "        -0.8112745 , -0.91115195, -0.9660539 , -0.9988971 , -0.6156863 ,\n",
       "        -0.67058825, -0.7176471 , -0.714951  , -0.76985294, -0.8482843 ,\n",
       "        -0.9216912 , -0.9773284 , -0.99485296, -0.39644608, -0.40428922,\n",
       "        -0.4435049 , -0.3004902 , -0.26127452, -0.30833334, -0.2709559 ,\n",
       "        -0.23174019, -0.26311275, -0.50735295, -0.49166667, -0.53088236,\n",
       "        -0.3732843 , -0.36544117, -0.40465686, -0.55220586, -0.5443627 ,\n",
       "        -0.59142154, -0.52340686, -0.5155637 , -0.56262255, -0.53125   ,\n",
       "        -0.52340686, -0.56262255, -0.53088236, -0.5387255 , -0.5779412 ,\n",
       "        -0.35514706, -0.3865196 , -0.47279412, -0.60759807, -0.6389706 ,\n",
       "        -0.7252451 , -0.60355395, -0.6584559 , -0.7368873 , -0.88161767,\n",
       "        -0.9129902 , -0.97132355, -0.735049  , -0.80563724, -0.8762255 ,\n",
       "        -0.88370097, -0.94644606, -0.96213233, -0.4716912 , -0.7636029 ,\n",
       "        -0.7683824 , -0.5324755 , -0.49632353, -0.47279412, -0.38517156,\n",
       "        -0.34595588, -0.38688725, -0.55330884, -0.53112745, -0.52977943,\n",
       "        -0.47683823, -0.44375   , -0.49387255, -0.36164215, -0.31458333,\n",
       "        -0.3302696 , -0.38688725, -0.35245097, -0.3694853 , -0.2927696 ,\n",
       "        -0.2675245 , -0.2814951 , -0.44889706, -0.40490195, -0.42671567,\n",
       "        -0.41311276, -0.3408088 , -0.32512254, -0.4283088 , -0.47536764,\n",
       "        -0.5694853 , -0.35784313, -0.38921568, -0.47549018, -0.3442402 ,\n",
       "        -0.37561274, -0.44620097, -0.66384804, -0.6952206 , -0.7658088 ,\n",
       "        -0.87352943, -0.9127451 , -0.94411767, -0.5974265 , -0.628799  ,\n",
       "        -0.69938725, -0.1430147 , -0.26066175, -0.29987746, -0.4970588 ,\n",
       "        -0.5561274 , -0.60110295, -0.27585784, -0.30723038, -0.3819853 ,\n",
       "        -0.4237745 , -0.47867647, -0.5414216 , -0.48602942, -0.49178922,\n",
       "        -0.5372549 , -0.529902  , -0.4985294 , -0.49068627, -0.64816177,\n",
       "        -0.60318625, -0.5969363 , -0.5915441 , -0.52095586, -0.4817402 ,\n",
       "        -0.4922794 , -0.3824755 , -0.31188726, -0.48443627, -0.39031863,\n",
       "        -0.39031863, -0.57463235, -0.6295343 , -0.7079657 , -0.6719363 ,\n",
       "        -0.72683823, -0.8052696 , -0.4677696 , -0.51482844, -0.6089461 ,\n",
       "        -0.57941175, -0.6107843 , -0.6970588 , -0.5512255 , -0.58259803,\n",
       "        -0.6767157 , -0.7997549 , -0.8546569 , -0.93308824, -0.8122549 ,\n",
       "        -0.86715686, -0.94558823, -0.25232843, -0.33860293, -0.3542892 ,\n",
       "        -0.4105392 , -0.43406862, -0.4732843 , -0.5275735 , -0.51911765,\n",
       "        -0.5052696 , -0.5457108 , -0.55355394, -0.5927696 , -0.45281863,\n",
       "        -0.48357844, -0.5529412 , -0.46666667, -0.48897058, -0.52818626,\n",
       "        -0.49191177, -0.41286764, -0.4865196 , -0.36531863, -0.42022058,\n",
       "        -0.4672794 , -0.46789217, -0.49142158, -0.54632354, -0.6185049 ,\n",
       "        -0.6655637 , -0.75968134, -0.4625    , -0.5095588 , -0.6193628 ,\n",
       "        -0.5873774 , -0.6422794 , -0.76776963, -0.17438726, -0.26066175,\n",
       "        -0.41752452, -0.24877451, -0.3507353 , -0.4997549 , -0.18308823,\n",
       "        -0.24583334, -0.39485294, -0.50625   , -0.5644608 , -0.6800245 ,\n",
       "        -0.15012255, -0.20502451, -0.28345588, -0.41838235, -0.47659314,\n",
       "        -0.5921569 , -0.42622548, -0.4497549 , -0.49803922, -0.5240196 ,\n",
       "        -0.49803922, -0.5029412 , -0.23382352, -0.30441177, -0.35931373,\n",
       "        -0.27144608, -0.30281863, -0.38909313, -0.38492647, -0.44436276,\n",
       "        -0.52732843, -0.4612745 , -0.50625   , -0.58137256, -0.42291668,\n",
       "        -0.45428923, -0.5405637 , -0.8574755 , -0.9202206 , -0.9981618 ,\n",
       "        -0.22904412, -0.2917892 , -0.47218138, -0.15294118, -0.23921569,\n",
       "        -0.38039216, -0.2180147 , -0.28860295, -0.42193627, -0.23186274,\n",
       "        -0.31813726, -0.45931372, -0.13308823, -0.20367648, -0.33700982,\n",
       "        -0.23137255, -0.28627452, -0.4117647 , -0.6933824 , -0.7224265 ,\n",
       "        -0.81985295, -0.29460785, -0.35735294, -0.45931372, -0.3375    ,\n",
       "        -0.4002451 , -0.4865196 , -0.31764707, -0.38039216, -0.46666667,\n",
       "        -0.36237746, -0.4057598 , -0.49987745, -0.32181373, -0.3767157 ,\n",
       "        -0.45514706, -0.40625   , -0.43762255, -0.52389705, -0.2977941 ,\n",
       "        -0.32916668, -0.4154412 , -0.36838236, -0.3997549 , -0.48602942,\n",
       "        -0.05098039, -0.10588235, -0.24705882, -0.10061274, -0.17120098,\n",
       "        -0.30453432, -0.12242647, -0.19301471, -0.32634804, -0.1754902 ,\n",
       "        -0.24607843, -0.37941176, -0.16164216, -0.2322304 , -0.34987745,\n",
       "        -0.24791667, -0.31066176, -0.41262254, -0.31066176, -0.37340686,\n",
       "        -0.47536764, -0.22352941, -0.3019608 , -0.39607844, -0.28541666,\n",
       "        -0.36384803, -0.45796567, -0.3420343 , -0.42046568, -0.51458335,\n",
       "        -0.33333334, -0.39607844, -0.49803922, -0.24264705, -0.30539215,\n",
       "        -0.40735295, -0.38455883, -0.38541666, -0.44558823, -0.4997549 ,\n",
       "        -0.50759804, -0.5372549 , -0.54068625, -0.56421566, -0.6818628 ,\n",
       "        -0.30808824, -0.35514706, -0.4492647 , -0.2192402 , -0.31335783,\n",
       "        -0.43884805, -0.20220588, -0.27279413, -0.40612745, -0.13799019,\n",
       "        -0.20857844, -0.34191176, -0.15943627, -0.22144608, -0.35049018,\n",
       "        -0.12303922, -0.19362745, -0.3112745 , -0.1757353 , -0.23848039,\n",
       "        -0.34044117, -0.17720588, -0.23995098, -0.34191176, -0.16078432,\n",
       "        -0.22352941, -0.3254902 , -0.25061274, -0.31335783, -0.41531864,\n",
       "        -0.31764707, -0.3718137 , -0.46948528, -0.31262255, -0.37536764,\n",
       "        -0.46164215, -0.2720588 , -0.3262255 , -0.42389706, -0.21642157,\n",
       "        -0.27916667, -0.37254903, -0.39681372, -0.4716912 , -0.5764706 ,\n",
       "        -0.32193628, -0.39178923, -0.48161766, -0.26764706, -0.32254902,\n",
       "        -0.40098038, -0.04791667, -0.1185049 , -0.25183824, -0.21262255,\n",
       "        -0.29889706, -0.44007352, -0.2517157 , -0.32230392, -0.45563725,\n",
       "        -0.15625   , -0.22683823, -0.36017156, -0.0557598 , -0.10281863,\n",
       "        -0.20943627, -0.11053921, -0.15759803, -0.26740196, -0.15294118,\n",
       "        -0.2       , -0.30980393, -0.2297794 , -0.29252452, -0.3944853 ,\n",
       "        -0.20625   , -0.25330883, -0.36311275, -0.21568628, -0.2627451 ,\n",
       "        -0.35686275, -0.24705882, -0.30980393, -0.4117647 , -0.29093137,\n",
       "        -0.35367647, -0.43995097, -0.31764707, -0.3647059 , -0.45882353,\n",
       "        -0.34117648, -0.40392157, -0.49019608, -0.3302696 , -0.3930147 ,\n",
       "        -0.49178922, -0.3442402 , -0.39914215, -0.47757354, -0.12941177,\n",
       "        -0.18431373, -0.30980393, -0.1742647 , -0.22132353, -0.33112746,\n",
       "        -0.125     , -0.1877451 , -0.28970587, -0.12267157, -0.15404412,\n",
       "        -0.24816176, -0.0632353 , -0.09460784, -0.18872549, -0.10355392,\n",
       "        -0.15061274, -0.2447304 , -0.16078432, -0.20784314, -0.3019608 ,\n",
       "        -0.2930147 , -0.34791666, -0.47340685, -0.19546568, -0.2425245 ,\n",
       "        -0.33664215, -0.23700981, -0.26838234, -0.3625    , -0.16519608,\n",
       "        -0.2122549 , -0.30637255, -0.2       , -0.24705882, -0.34117648,\n",
       "        -0.22463235, -0.2795343 , -0.35796568, -0.42647058, -0.4735294 ,\n",
       "        -0.56764704, -0.23921569, -0.28627452, -0.38039216, -0.29742646,\n",
       "        -0.328799  , -0.41507354, -0.2824755 , -0.4079657 , -0.5175245 ,\n",
       "        -0.3290441 , -0.42316177, -0.54865193, -0.3055147 , -0.39963236,\n",
       "        -0.5175245 , -0.3435049 , -0.39031863, -0.5355392 , -0.30171567,\n",
       "        -0.36825982, -0.50968134, -0.27720588, -0.33210784, -0.4732843 ,\n",
       "        -0.2194853 , -0.2665441 , -0.36066177, -0.16862746, -0.23137255,\n",
       "        -0.33333334, -0.18406862, -0.23112746, -0.3409314 , -0.1569853 ,\n",
       "        -0.20404412, -0.29816177, -0.20784314, -0.25490198, -0.34901962,\n",
       "        -0.24375   , -0.29080883, -0.38492647, -0.24705882, -0.3019608 ,\n",
       "        -0.38039216, -0.2591912 , -0.29056373, -0.37683824, -0.27389705,\n",
       "        -0.3052696 , -0.3915441 , -0.27794117, -0.30147058, -0.41911766,\n",
       "        -0.38174018, -0.47585785, -0.60134804, -0.1672794 , -0.19080882,\n",
       "        -0.30845588, -0.40257353, -0.46531862, -0.5672794 , -0.28382352,\n",
       "        -0.33872548, -0.4642157 , -0.16348039, -0.21053922, -0.3360294 ,\n",
       "        -0.21323529, -0.26813725, -0.40931374, -0.23921569, -0.3019608 ,\n",
       "        -0.40392157, -0.3214461 , -0.3685049 , -0.47830883, -0.17781863,\n",
       "        -0.24056372, -0.3425245 , -0.19865195, -0.24571079, -0.3555147 ,\n",
       "        -0.23137255, -0.2784314 , -0.37254903, -0.23002452, -0.27708334,\n",
       "        -0.37120098, -0.26789215, -0.31495097, -0.4090686 , -0.2692402 ,\n",
       "        -0.31629902, -0.41041666, -0.24571079, -0.2927696 , -0.38688725,\n",
       "        -0.25355393, -0.25355393, -0.3319853 ]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape전 batch, 14, 14, patch별 dimension\n",
    "make_patches = Patches(16)\n",
    "patches = make_patches(image)\n",
    "patches[:,1,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(image[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        patch = tf.reshape(patches[:,i,j,:],[16,16,3]).numpy()\n",
    "        plt.subplot(2,2,i*2+j+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(patch)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_patches.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch Embedding에 통합됨\n",
    "\n",
    "class PatchProjection(tf.keras.layers.Layer):\n",
    "    # equal to a dense layer without bias and activation\n",
    "    # just embedding matrix = tf.keras.layers.Embedding\n",
    "    # NOTE in hybrid architecture, patch projection is replaced with CNN feature extractor\n",
    "    def __init__(self, patch_size, projection_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size = patch_size\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection = tf.keras.layers.Dense(units=projection_dim)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        patches = self.make_patches(inputs)\n",
    "        patch_shape = patches.shape\n",
    "        patch_nums = patch_shape[1]*patch_shape[2]\n",
    "        \n",
    "        y = self.projection(patches)\n",
    "        return y      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = tf.Variable(tf.random.normal([1,1,10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.initializers.initializers_v2.GlorotNormal at 0x7f2000582be0>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.initializers.GlorotNormal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(tf.keras.layers.Layer):\n",
    "    # 1. add dummy patch and project patches to projection dimension \n",
    "    # 2. attach position embeddings to each patches \n",
    "    # NOTE add extra learnable class embedding to dummy patch\n",
    "\n",
    "    def __init__(self, projection_dim, dropout_rate, **kwargs):\n",
    "        super().__init__( **kwargs)\n",
    "        self.projection_dim = projection_dim\n",
    "        self.projection = tf.keras.layers.Dense(units=self.projection_dim, trainable=True)     \n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)   \n",
    "        self.class_token = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "    def build(self,input_shape): \n",
    "        # input_shape는 (batch, patch수, patch별 dimension)\n",
    "        self.patch_nums = input_shape[1]\n",
    "        self.batch_size = input_shape[0]\n",
    "        self.position_embedding = tf.keras.layers.Embedding(input_dim=self.patch_nums, output_dim=self.projection_dim, trainable=True)\n",
    "        self.class_token = tf.Variable(\n",
    "            tf.random.normal([1,1, self.projection_dim]),# from BERT / TODO normal(stddev=0.02)\n",
    "            trainable=True,\n",
    "            name='class token (=projected dummy patch)',\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        positions = tf.range(start=0, limit=self.patch_nums+1)                  # class token을 위해 +1\n",
    "        y1 = self.projection(inputs)                                            # batch, patch개수, projection dimension\n",
    "        self.class_token = tf.cast(self.class_token, tf.float32)\n",
    "        \n",
    "        print(\"class token:\",self.class_token.shape)\n",
    "        print(\"y1 shape:\", y1.shape)\n",
    "        print(\"input batch size:\",self.batch_size)\n",
    "        if self.batch_size != 1:# 여기가 None인 경우가 있어 의도대로 처리가 안될수도\n",
    "        #NOTE broadcasting을 BATCH_SIZE로 고정하면서 이미지 하나가 들어오는 상황을 처리 못함.\n",
    "            print(\"class token need broadcast to batch axis\")\n",
    "            print(\"type of class token:\", type(self.class_token))\n",
    "            self.class_token = tf.broadcast_to(self.class_token, shape=[BATCH_SIZE,1,self.projection_dim])\n",
    "            print(\"class token:\",self.class_token.shape)\n",
    "            \n",
    "        y1 = tf.concat([self.class_token,y1], axis=1)                           # batch, patch개수 + 1, projeciton dimension\n",
    "        print(\"number of patches after add dummy class patch:\", y1.shape)\n",
    "        print(\"y1:\",y1.shape)\n",
    "        y2 = self.position_embedding(positions)\n",
    "        output = y1+y2\n",
    "        output = self.dropout(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 1, 100), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., ..., 1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.ones([1,1,100])\n",
    "tf.broadcast_to(A, [256,1,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchEmbedding = PatchEmbedding(projection_dim=100,name='patch embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patchEmbedding.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 768) -> (1, 4, 768)\n",
      "class token: (1, 1, 100)\n",
      "y1 shape: (1, 4, 100)\n",
      "input batch size: 1\n",
      "number of patches after add dummy class patch: (1, 5, 100)\n",
      "y1: (1, 5, 100)\n"
     ]
    }
   ],
   "source": [
    "reshaped_patches = tf.reshape(patches, [-1,2*2, patches.shape[-1]])\n",
    "print(patches.shape, \"->\", reshaped_patches.shape)\n",
    "embedded_patches = patchEmbedding(reshaped_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patchEmbedding.variables) \n",
    "# expect 4 (dense kernel, dense bias, embedding kernel, class token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras의 multiheadattention layer 사용\n",
    "# transformer encoder에 통합됨\n",
    "\n",
    "class MSA(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, heads_num, key_dim,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.heads_num = heads_num\n",
    "        self.key_dim = key_dim\n",
    "\n",
    "        self.initializer = tf.keras.initializers.RandomNormal()\n",
    "        \n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input shape (batch, patch개수+1, patch별 dimension)\n",
    "\n",
    "        self.m_qkv = tf.Variable(\n",
    "            self.initializer(input_shape[-1], self.key_dim),\n",
    "            name=\"qkv matrix\",\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "\n",
    "    def call(self, inputs):\n",
    "        qkv = tf.matmul(inputs, self.m_qkv)\n",
    "        print(qkv.shape)\n",
    "        q = \n",
    "        k = \n",
    "        v = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multihead attention layer를 이해해보자 <br>\n",
    "multihead self attention으로 만들기 위해서는 attention layer의 target과 source에 같은 값을 넣으면 됨.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 167, 100)\n",
      "(None, 167, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=50, value_dim=100 ,use_bias=False, attention_axes=(2), output_shape=(100))\n",
    "input = tf.keras.Input(shape=[167, 100])\n",
    "attention_output, attention_scores = attention_layer(input, input,\n",
    "                               return_attention_scores=True)\n",
    "print(attention_output.shape)\n",
    "print(attention_scores.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 197, 100)\n",
      "(1, 197, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=50, value_dim=50 ,use_bias=False, attention_axes=(2))\n",
    "norm_patches = tf.keras.layers.LayerNormalization()(embedded_patches)\n",
    "output_tensor, weights = attention_layer(norm_patches, norm_patches,\n",
    "                               return_attention_scores=True)\n",
    "print(output_tensor.shape)\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attention_layer.variables) #W_k, W_q, W_v, W_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.layers.Layer):\n",
    "    # MLP layer for transformer encoder\n",
    "    # two layers with a GELU non-linearity\n",
    "\n",
    "    # dense-gelu-dropout-dense-dropout\n",
    "    def __init__(self, output_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_size = output_size\n",
    "        self.dense_1 = tf.keras.layers.Dense(output_size, activation=tf.nn.gelu, trainable=True)\n",
    "        self.dense_2 = tf.keras.layers.Dense(output_size, activation=tf.nn.gelu, trainable=True)\n",
    "        # TODO kernel은 xavier uniform/ bias는 normal(stddev=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        y = self.dense_1(inputs)\n",
    "        y = self.dense_2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLP(100)\n",
    "mlp.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp(tf.constant([[2,2,2]]))\n",
    "len(mlp.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    # input : embedded patches (batch, patch개수+1, projection_dim)\n",
    "    # logic : norm -> MSA -> (skip-connection) -> norm -> MLP -> (skip-connection)\n",
    "    # NOTE MSA is global and MLP is local\n",
    "\n",
    "    def __init__(self, heads_num, hidden_dim, output_dim, dropout, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.heads_num = heads_num\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.norm = tf.keras.layers.LayerNormalization(axis=2)\n",
    "        \n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # create the state of the layer (weights)\n",
    "        # print(\"output_shape:\",(-1,input_shape[1],self.hidden_dim) )\n",
    "        self.MSA = tf.keras.layers.MultiHeadAttention( # TODO xavier_uniform/ broadcast dropout=False\n",
    "            num_heads=self.heads_num, \n",
    "            key_dim=self.hidden_dim, \n",
    "            value_dim=self.hidden_dim, \n",
    "            \n",
    "            dropout=self.dropout, \n",
    "            use_bias=False, \n",
    "            #output_shape=(-1,input_shape[1],self.hidden_dim),\n",
    "            attention_axes=(1,2),\n",
    "\n",
    "            kernel_initializer=tf.keras.initializers.GlorotNormal(), # called Xavier normal \n",
    "            trainable = True\n",
    "        )\n",
    "        self.mlp = MLP(self.output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        norm1 = self.norm(inputs)                                                       # shape변화가 생기진 않음. (batch, patch수+1, projection_dim)\n",
    "        attention_output, attention_scores = self.MSA(norm1, norm1, return_attention_scores=True)\n",
    "        # print(\"inputs shape:\", inputs.shape)\n",
    "        # print(\"attention_output shape:\", attention_output.shape)\n",
    "        skip_connection1 = attention_output+inputs\n",
    "\n",
    "        norm2 = self.norm(skip_connection1)\n",
    "        mlp = self.mlp(norm2)\n",
    "        # print(\"skip connection:\", skip_connection1.shape)\n",
    "        # print(\"mlp output:\", mlp.shape)\n",
    "        output = mlp + skip_connection1\n",
    "        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 197, 100), dtype=float32, numpy=\n",
       "array([[[-0.83978915,  0.11540891,  0.8937869 , ...,  0.00642251,\n",
       "          1.0879207 ,  0.7042538 ],\n",
       "        [ 0.76290274, -1.2995269 , -0.7969871 , ..., -0.3934379 ,\n",
       "         -0.05691993, -0.26764238],\n",
       "        [ 0.6531043 , -1.2234181 , -0.66665035, ..., -0.15550154,\n",
       "          0.09102231, -0.32065767],\n",
       "        ...,\n",
       "        [ 0.12630479,  0.23560578, -0.38768417, ..., -0.1849199 ,\n",
       "          0.319824  ,  0.67517996],\n",
       "        [ 0.09697765,  0.37452912, -0.35579357, ..., -0.22407901,\n",
       "          0.4779696 ,  0.6551471 ],\n",
       "        [ 0.13296945,  0.04415721, -0.4646786 , ..., -0.21531425,\n",
       "          0.31047422,  0.6736077 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = TransformerEncoder(heads_num=8,hidden_dim=50,output_dim=100,dropout=0.5)\n",
    "transformer(embedded_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transformer.variables) # 2 for layer norm/ 4 for MSA/ 4 for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'transformer_encoder/layer_normalization_2/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder/layer_normalization_2/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder/multi_head_attention_3/query/kernel:0' shape=(100, 8, 50) dtype=float32, numpy=\n",
       " array([[[ 0.02190404,  0.01794252,  0.00098116, ..., -0.00282094,\n",
       "          -0.00379554, -0.03125364],\n",
       "         [-0.00764517,  0.01319864,  0.01687797, ..., -0.02421688,\n",
       "           0.01838562,  0.03023799],\n",
       "         [ 0.00172184, -0.00140594, -0.02413604, ..., -0.00634276,\n",
       "           0.01152133,  0.01100833],\n",
       "         ...,\n",
       "         [-0.01290493, -0.01785009,  0.01932432, ..., -0.02593914,\n",
       "          -0.02485238,  0.02117442],\n",
       "         [-0.01870706, -0.03193804,  0.00415726, ..., -0.00704693,\n",
       "           0.00181062, -0.01024361],\n",
       "         [ 0.02280842,  0.02026867,  0.01334282, ..., -0.01367418,\n",
       "          -0.00414647,  0.00092433]],\n",
       " \n",
       "        [[-0.00864271,  0.0207254 , -0.012448  , ..., -0.00610689,\n",
       "          -0.01144415,  0.00777214],\n",
       "         [ 0.0312059 , -0.0108776 , -0.01332078, ...,  0.00834616,\n",
       "          -0.01605951, -0.01775921],\n",
       "         [ 0.03103468,  0.0174039 ,  0.01687159, ..., -0.0046501 ,\n",
       "           0.01198311,  0.01783508],\n",
       "         ...,\n",
       "         [-0.01011099, -0.00442441, -0.0034307 , ..., -0.02009223,\n",
       "           0.0208869 , -0.02044998],\n",
       "         [ 0.01531718, -0.00760546, -0.02967909, ...,  0.00338794,\n",
       "          -0.03118269, -0.01173216],\n",
       "         [ 0.02677713,  0.02292511,  0.00470659, ...,  0.02977495,\n",
       "           0.0255377 ,  0.00776933]],\n",
       " \n",
       "        [[ 0.02039766, -0.01969714,  0.00715162, ..., -0.01791625,\n",
       "          -0.03158799,  0.01998407],\n",
       "         [ 0.03081171,  0.03089348,  0.01375042, ..., -0.01098541,\n",
       "          -0.01358184,  0.00637989],\n",
       "         [ 0.03079009,  0.01469948,  0.02620706, ...,  0.01392509,\n",
       "           0.03032056,  0.00315316],\n",
       "         ...,\n",
       "         [-0.00212172,  0.01723244,  0.01686526, ..., -0.00655897,\n",
       "           0.0022603 ,  0.00099272],\n",
       "         [-0.01765638,  0.02777128,  0.00322308, ..., -0.03079031,\n",
       "          -0.0243329 ,  0.01666189],\n",
       "         [ 0.01652911, -0.00608717, -0.02551829, ..., -0.01596538,\n",
       "          -0.00383752, -0.00912357]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.01607465,  0.00587526, -0.01268085, ...,  0.00916088,\n",
       "           0.01919423, -0.02117323],\n",
       "         [ 0.01492647,  0.00141713,  0.01446711, ...,  0.01564252,\n",
       "          -0.02285891,  0.01728125],\n",
       "         [ 0.02677445, -0.01444445,  0.02038793, ..., -0.01981956,\n",
       "          -0.01625907, -0.000265  ],\n",
       "         ...,\n",
       "         [ 0.02178106, -0.00897456,  0.0191599 , ..., -0.02651232,\n",
       "          -0.01227264, -0.0119581 ],\n",
       "         [-0.01446013,  0.02440613, -0.00736208, ..., -0.01627454,\n",
       "          -0.01786708, -0.02643866],\n",
       "         [ 0.02078845, -0.00592137,  0.01021158, ...,  0.02516235,\n",
       "          -0.02121327,  0.00641768]],\n",
       " \n",
       "        [[-0.01714763,  0.00140566, -0.00227616, ..., -0.0104232 ,\n",
       "           0.02201823, -0.00418161],\n",
       "         [ 0.01124322,  0.02092316,  0.03085185, ...,  0.00967562,\n",
       "           0.01393681, -0.02234082],\n",
       "         [-0.00181748, -0.0203568 ,  0.02122555, ..., -0.02082036,\n",
       "          -0.02314965, -0.02858899],\n",
       "         ...,\n",
       "         [-0.02429302,  0.00931044, -0.01679219, ..., -0.00408479,\n",
       "          -0.02780659,  0.01737262],\n",
       "         [-0.018851  ,  0.02358953,  0.0047111 , ...,  0.03105046,\n",
       "          -0.00235292,  0.02613371],\n",
       "         [ 0.00233192, -0.02439681, -0.01305974, ...,  0.01676308,\n",
       "          -0.03033139,  0.00259124]],\n",
       " \n",
       "        [[-0.02439405,  0.01796015,  0.00477744, ...,  0.03117236,\n",
       "           0.01884577, -0.01658923],\n",
       "         [ 0.02751979, -0.00492921, -0.02699901, ...,  0.01344507,\n",
       "           0.02165614,  0.01350966],\n",
       "         [-0.03111501,  0.02907953,  0.02209903, ...,  0.02100602,\n",
       "           0.0229158 , -0.00610833],\n",
       "         ...,\n",
       "         [-0.01060868,  0.02340971, -0.00588363, ..., -0.00325349,\n",
       "          -0.00711013, -0.0245999 ],\n",
       "         [ 0.03028623,  0.01615145, -0.02066394, ..., -0.00302316,\n",
       "           0.01527158,  0.0317294 ],\n",
       "         [ 0.02306343,  0.03103298, -0.00155855, ..., -0.01294024,\n",
       "          -0.02190542,  0.02316247]]], dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder/multi_head_attention_3/key/kernel:0' shape=(100, 8, 50) dtype=float32, numpy=\n",
       " array([[[ 2.83367410e-02, -2.65267361e-02, -1.62755977e-02, ...,\n",
       "          -2.56389491e-02, -2.97067240e-02,  1.92911923e-03],\n",
       "         [-2.77634636e-02, -1.00915525e-02,  6.47355616e-03, ...,\n",
       "          -2.88523398e-02, -2.04206780e-02,  2.54680216e-02],\n",
       "         [ 9.58332419e-03, -2.28069667e-02, -2.89764591e-02, ...,\n",
       "          -5.36031276e-03,  1.88496634e-02,  3.15437503e-02],\n",
       "         ...,\n",
       "         [ 3.16035412e-02,  1.50386095e-02, -1.95462778e-02, ...,\n",
       "           2.56649777e-03, -3.04025188e-02,  1.01650544e-02],\n",
       "         [ 2.06242576e-02,  3.11717726e-02,  1.81247443e-02, ...,\n",
       "           1.69149861e-02,  6.77594915e-03,  1.81953385e-02],\n",
       "         [ 1.85424462e-03,  4.19764593e-03, -1.92345865e-03, ...,\n",
       "           3.17581184e-02, -1.16704497e-02,  2.14705244e-03]],\n",
       " \n",
       "        [[ 9.38389450e-04,  2.74211876e-02, -2.63704788e-02, ...,\n",
       "          -1.38679706e-03,  3.19840126e-02, -1.81379952e-02],\n",
       "         [-3.08970492e-02,  5.62749431e-03, -4.95241024e-03, ...,\n",
       "           2.39182934e-02,  2.08062269e-02,  6.77665696e-03],\n",
       "         [-1.76250357e-02,  9.53264534e-03, -3.99881229e-03, ...,\n",
       "           3.19382735e-02,  5.87887689e-03,  1.05991811e-02],\n",
       "         ...,\n",
       "         [-2.94035096e-02,  2.91363969e-02, -3.20507511e-02, ...,\n",
       "          -1.82715245e-02,  2.47580484e-02,  2.70157009e-02],\n",
       "         [ 6.24480098e-03, -1.08473971e-02, -5.08147664e-03, ...,\n",
       "          -1.42529495e-02, -1.69139653e-02,  3.09893079e-02],\n",
       "         [ 2.27518007e-02, -2.75031999e-02,  2.65348256e-02, ...,\n",
       "           2.51669995e-02, -1.39777474e-02,  5.60602173e-03]],\n",
       " \n",
       "        [[-1.95230823e-02, -4.39451449e-03,  2.04420462e-03, ...,\n",
       "          -5.43895923e-03, -1.81572028e-02, -2.19477136e-02],\n",
       "         [-1.01053622e-02,  2.03623585e-02,  1.33855529e-02, ...,\n",
       "           2.47336105e-02,  2.11249851e-02,  2.55540125e-02],\n",
       "         [-3.06018870e-02, -2.15648636e-02, -3.46241891e-03, ...,\n",
       "          -6.72625192e-03,  3.99418920e-03,  1.26316324e-02],\n",
       "         ...,\n",
       "         [ 3.03100236e-02, -2.81206183e-02, -1.47182792e-02, ...,\n",
       "          -9.36073624e-03, -1.92123223e-02,  1.43510439e-02],\n",
       "         [-1.35003310e-02, -9.63058509e-03,  6.15776703e-03, ...,\n",
       "           2.10145079e-02,  2.46638432e-03, -1.90685559e-02],\n",
       "         [ 2.42719725e-02,  8.30333307e-03, -2.36562062e-02, ...,\n",
       "          -1.26263928e-02, -1.63088255e-02,  1.77765302e-02]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2.69096568e-02,  6.67547062e-03,  1.59096718e-03, ...,\n",
       "           2.20467187e-02,  2.35345848e-02,  1.85757875e-03],\n",
       "         [-2.68234164e-02, -1.56518631e-02,  7.69307837e-03, ...,\n",
       "           1.59116350e-02, -2.33779587e-02,  1.41829997e-02],\n",
       "         [ 3.97894531e-03,  4.51756269e-03, -2.22518481e-02, ...,\n",
       "           3.09239291e-02,  2.80631892e-02,  2.73222476e-03],\n",
       "         ...,\n",
       "         [ 1.87523887e-02, -1.65856145e-02,  1.28199570e-02, ...,\n",
       "           1.21319368e-02,  5.26336953e-03, -2.63890978e-02],\n",
       "         [-2.83703450e-02, -1.67344026e-02,  9.11100209e-03, ...,\n",
       "           2.02417597e-02, -3.17199156e-02, -2.38885023e-02],\n",
       "         [ 9.46810097e-03, -3.82533856e-03,  1.29793361e-02, ...,\n",
       "           3.15137468e-02,  7.72591308e-03, -1.43753737e-02]],\n",
       " \n",
       "        [[ 3.95847112e-03, -7.16861337e-04, -2.42479555e-02, ...,\n",
       "           1.58642009e-02,  2.68913358e-02, -2.01261118e-02],\n",
       "         [-9.75046307e-04, -1.45442076e-02,  1.40295327e-02, ...,\n",
       "          -1.36516970e-02,  4.94217128e-03,  3.11721377e-02],\n",
       "         [ 1.63886361e-02,  1.68801546e-02, -9.64562222e-03, ...,\n",
       "           4.23802063e-03,  1.02028735e-02, -2.02185623e-02],\n",
       "         ...,\n",
       "         [ 2.42898352e-02, -2.46431455e-02, -1.50697511e-02, ...,\n",
       "           2.41824761e-02,  1.62646472e-02,  2.06222013e-02],\n",
       "         [ 2.55088843e-02, -2.65029799e-02, -2.92456485e-02, ...,\n",
       "          -1.27508510e-02, -1.47057045e-02,  1.23736821e-02],\n",
       "         [-1.48062669e-02,  1.60627067e-04, -9.96731780e-03, ...,\n",
       "          -9.22624767e-03,  2.05351412e-03,  2.54998840e-02]],\n",
       " \n",
       "        [[-1.64982565e-02, -6.59601204e-03,  1.03963688e-02, ...,\n",
       "          -3.07993945e-02,  9.71229002e-03,  6.93414733e-03],\n",
       "         [-3.13025527e-02, -2.95382570e-02, -5.20298071e-03, ...,\n",
       "          -5.50377928e-03,  3.20779420e-02,  2.79757641e-02],\n",
       "         [-7.32574798e-03, -9.73418355e-05, -2.46324483e-02, ...,\n",
       "           3.21031697e-02,  1.28604472e-03, -1.29846893e-02],\n",
       "         ...,\n",
       "         [ 1.14039592e-02, -3.18581760e-02,  3.08520459e-02, ...,\n",
       "           1.63874030e-03,  4.12885100e-03, -1.72087662e-02],\n",
       "         [-2.78763659e-02,  8.79724324e-03, -1.72084142e-02, ...,\n",
       "           1.02368370e-02, -2.43760347e-02,  1.16432123e-02],\n",
       "         [-1.79404877e-02,  1.32807344e-03,  6.58366829e-03, ...,\n",
       "          -1.54043213e-02,  2.33114213e-02,  7.84361362e-03]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder/multi_head_attention_3/value/kernel:0' shape=(100, 8, 50) dtype=float32, numpy=\n",
       " array([[[ 0.01777551,  0.00758212, -0.02635565, ..., -0.00538157,\n",
       "          -0.02786818,  0.00942389],\n",
       "         [ 0.01743381,  0.02460699,  0.0311398 , ...,  0.02831941,\n",
       "          -0.01551156,  0.01685227],\n",
       "         [-0.02515123, -0.0104542 ,  0.00133976, ...,  0.02682303,\n",
       "          -0.00932897,  0.02021037],\n",
       "         ...,\n",
       "         [-0.02698685,  0.00345049,  0.01392582, ..., -0.02097828,\n",
       "          -0.01868837,  0.03008569],\n",
       "         [ 0.0161798 ,  0.02396417,  0.01431623, ..., -0.03172075,\n",
       "           0.01263876,  0.00015824],\n",
       "         [-0.01153784, -0.00092454,  0.00089755, ..., -0.00798371,\n",
       "           0.00025795, -0.00291859]],\n",
       " \n",
       "        [[-0.01388168, -0.0132344 ,  0.00913258, ...,  0.0133155 ,\n",
       "          -0.01585634,  0.03081777],\n",
       "         [-0.01627479, -0.00716727,  0.000368  , ...,  0.02300914,\n",
       "           0.00910471, -0.006769  ],\n",
       "         [ 0.01189044,  0.00531754,  0.0053198 , ...,  0.02514747,\n",
       "          -0.01785154,  0.02034863],\n",
       "         ...,\n",
       "         [ 0.00669342,  0.00941119, -0.00860826, ..., -0.0219726 ,\n",
       "          -0.01196313, -0.00919919],\n",
       "         [-0.02325571,  0.0173182 , -0.02287436, ..., -0.02440588,\n",
       "          -0.01586915, -0.02277623],\n",
       "         [ 0.01513813,  0.00040951,  0.01396627, ...,  0.0020705 ,\n",
       "          -0.01290694,  0.0035694 ]],\n",
       " \n",
       "        [[-0.00687981,  0.0289852 , -0.00366651, ..., -0.01903454,\n",
       "           0.02690615,  0.01347467],\n",
       "         [ 0.02547588, -0.0317247 , -0.02101491, ..., -0.01372392,\n",
       "          -0.0048338 ,  0.02490716],\n",
       "         [ 0.02124326,  0.0127435 , -0.02411782, ..., -0.01760998,\n",
       "           0.01583528, -0.00037622],\n",
       "         ...,\n",
       "         [ 0.01614936,  0.0158584 ,  0.01949457, ...,  0.01206056,\n",
       "           0.01623791,  0.00306353],\n",
       "         [ 0.02078953, -0.02075116, -0.01343537, ...,  0.02252954,\n",
       "           0.02477015,  0.01293784],\n",
       "         [ 0.02903927, -0.0277172 ,  0.00245072, ..., -0.02920425,\n",
       "           0.03186778,  0.00342741]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.00897692, -0.02755494,  0.03011644, ..., -0.00785608,\n",
       "          -0.0091916 , -0.01559759],\n",
       "         [-0.01568338,  0.01783046, -0.02044186, ..., -0.02310898,\n",
       "          -0.00830761, -0.01382187],\n",
       "         [ 0.02336915,  0.00023325,  0.0005623 , ...,  0.000921  ,\n",
       "          -0.00181998,  0.00664368],\n",
       "         ...,\n",
       "         [-0.00754092, -0.02925499, -0.0299456 , ...,  0.00546044,\n",
       "          -0.03094272, -0.01937375],\n",
       "         [-0.03064842,  0.02367398, -0.01888146, ..., -0.02104967,\n",
       "           0.0046902 , -0.00764451],\n",
       "         [-0.00890574,  0.01629439,  0.02492641, ...,  0.01803483,\n",
       "          -0.01714138,  0.02658955]],\n",
       " \n",
       "        [[ 0.02806223, -0.00159341, -0.00773809, ...,  0.03200307,\n",
       "           0.01792898,  0.00446477],\n",
       "         [-0.00720282,  0.02439378,  0.02094221, ..., -0.03159124,\n",
       "           0.02574794, -0.02862428],\n",
       "         [ 0.01791432, -0.00522849, -0.01260969, ...,  0.0180011 ,\n",
       "          -0.01716875, -0.02634725],\n",
       "         ...,\n",
       "         [ 0.02617366, -0.01090052,  0.01769823, ..., -0.02047285,\n",
       "          -0.019239  ,  0.01851859],\n",
       "         [ 0.01056157,  0.03026726, -0.00604969, ..., -0.00672309,\n",
       "          -0.02043939,  0.01350348],\n",
       "         [ 0.00651293,  0.00826058, -0.02373256, ...,  0.01167481,\n",
       "          -0.03076391,  0.00295905]],\n",
       " \n",
       "        [[-0.02638238,  0.00873833,  0.02153438, ..., -0.00099903,\n",
       "          -0.02816303,  0.00866334],\n",
       "         [-0.02549753,  0.01360458, -0.01251757, ...,  0.00324387,\n",
       "          -0.01098008,  0.01034814],\n",
       "         [ 0.01016945, -0.01946776, -0.01475302, ..., -0.01540095,\n",
       "          -0.01804033,  0.02914328],\n",
       "         ...,\n",
       "         [-0.00218849,  0.01981173,  0.00068185, ..., -0.02335391,\n",
       "           0.02217677, -0.0103056 ],\n",
       "         [-0.00761159,  0.02929723,  0.00166231, ..., -0.018553  ,\n",
       "           0.00795338, -0.01580107],\n",
       "         [-0.03165554,  0.00547782, -0.02107248, ..., -0.01716346,\n",
       "          -0.00326681,  0.02524015]]], dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder/multi_head_attention_3/attention_output/kernel:0' shape=(8, 50, 100) dtype=float32, numpy=\n",
       " array([[[ 0.04439503, -0.03640635, -0.03119578, ..., -0.06890979,\n",
       "           0.00251517,  0.06345699],\n",
       "         [-0.03647621,  0.04978344,  0.02275845, ...,  0.04029025,\n",
       "          -0.0107241 , -0.01691289],\n",
       "         [-0.02306409,  0.03206925, -0.01151688, ...,  0.03307177,\n",
       "           0.06338675, -0.0310585 ],\n",
       "         ...,\n",
       "         [ 0.01760594, -0.04417754, -0.01227542, ..., -0.0139397 ,\n",
       "           0.02597888,  0.0686947 ],\n",
       "         [ 0.06583934,  0.00124067,  0.05934327, ...,  0.02500489,\n",
       "           0.01167053,  0.00532303],\n",
       "         [-0.03661245,  0.0698643 , -0.00191989, ...,  0.05661853,\n",
       "          -0.00392883, -0.00727612]],\n",
       " \n",
       "        [[ 0.03441639, -0.02603807,  0.0455277 , ...,  0.01377568,\n",
       "           0.04716418, -0.00422843],\n",
       "         [-0.03949674,  0.02354784, -0.06137182, ..., -0.04066261,\n",
       "           0.01236774, -0.00010751],\n",
       "         [-0.05150812,  0.00113097,  0.05443262, ..., -0.00086688,\n",
       "          -0.00430956,  0.02904499],\n",
       "         ...,\n",
       "         [-0.00866086,  0.04754905,  0.06820785, ..., -0.04090743,\n",
       "          -0.05776715,  0.04327206],\n",
       "         [ 0.01653749,  0.05679136,  0.05705617, ...,  0.01199932,\n",
       "           0.02407324,  0.02042747],\n",
       "         [-0.02556807,  0.04325856, -0.06000793, ..., -0.00814636,\n",
       "          -0.02886489, -0.02091571]],\n",
       " \n",
       "        [[ 0.01219706,  0.00878848, -0.01140381, ..., -0.04170095,\n",
       "           0.0177562 ,  0.00917004],\n",
       "         [ 0.00678261,  0.0341376 ,  0.03354581, ...,  0.03643251,\n",
       "           0.0294668 , -0.0161499 ],\n",
       "         [-0.06031027, -0.01254214,  0.06101006, ...,  0.01921631,\n",
       "          -0.01243684,  0.05736914],\n",
       "         ...,\n",
       "         [ 0.0397175 , -0.01260965,  0.04676089, ..., -0.01956909,\n",
       "          -0.06020772,  0.02855316],\n",
       "         [-0.07014924,  0.04243247,  0.03846591, ...,  0.01396391,\n",
       "           0.03745741,  0.06715057],\n",
       "         [-0.0064236 , -0.0178175 , -0.06771777, ...,  0.0109653 ,\n",
       "          -0.04403275,  0.02460579]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.04572286,  0.05634419,  0.00113758, ...,  0.05236062,\n",
       "          -0.06283165,  0.04306118],\n",
       "         [ 0.03528398,  0.00375284, -0.04466804, ..., -0.0525714 ,\n",
       "           0.03738997, -0.01247896],\n",
       "         [-0.02594088, -0.00161423, -0.03440651, ..., -0.03068963,\n",
       "          -0.06271003, -0.02105965],\n",
       "         ...,\n",
       "         [ 0.04217903, -0.00834912,  0.01855253, ...,  0.02998543,\n",
       "           0.05304643, -0.0145204 ],\n",
       "         [ 0.01071482, -0.02495329, -0.02719293, ...,  0.06769825,\n",
       "          -0.07040899,  0.04770469],\n",
       "         [ 0.00132732, -0.0697355 ,  0.01607774, ..., -0.00860905,\n",
       "           0.03719839, -0.05835773]],\n",
       " \n",
       "        [[ 0.01824569, -0.00780216, -0.05370434, ...,  0.04473618,\n",
       "           0.05710826,  0.01384871],\n",
       "         [ 0.05366316, -0.05695872,  0.03966224, ..., -0.05619065,\n",
       "          -0.01336222,  0.0426138 ],\n",
       "         [ 0.02645005, -0.04582029,  0.00050237, ..., -0.01589673,\n",
       "          -0.04118842, -0.01015306],\n",
       "         ...,\n",
       "         [-0.06325123,  0.05555081,  0.00013448, ..., -0.02609141,\n",
       "          -0.03261847, -0.01235558],\n",
       "         [-0.02520746, -0.02789855,  0.03672742, ...,  0.03164478,\n",
       "          -0.06279011, -0.02027041],\n",
       "         [-0.01679661, -0.03582233,  0.05542613, ..., -0.05274739,\n",
       "           0.06521944,  0.06755116]],\n",
       " \n",
       "        [[-0.03682183, -0.02455654, -0.04110166, ...,  0.02988839,\n",
       "           0.00468666,  0.06605167],\n",
       "         [-0.00257482, -0.0491055 ,  0.00036272, ..., -0.02361893,\n",
       "           0.05530233, -0.02456895],\n",
       "         [-0.02628854, -0.03634994, -0.01073121, ...,  0.06409013,\n",
       "          -0.00344034,  0.0080621 ],\n",
       "         ...,\n",
       "         [-0.05435656,  0.04942273,  0.0389816 , ..., -0.04680537,\n",
       "          -0.0503173 , -0.04829682],\n",
       "         [ 0.01178671,  0.03242214, -0.0619538 , ..., -0.05015079,\n",
       "           0.01693913,  0.00090287],\n",
       "         [-0.0038616 ,  0.03625366, -0.02141926, ...,  0.07052385,\n",
       "          -0.03734228,  0.01087495]]], dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder/mlp_1/dense_12/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.11048746, -0.11324792,  0.14707181, ..., -0.13484785,\n",
       "          0.08211511, -0.03970581],\n",
       "        [ 0.14285287, -0.04411376, -0.01854585, ..., -0.1312486 ,\n",
       "          0.11975396,  0.09166089],\n",
       "        [-0.0023554 ,  0.08688965,  0.11221084, ...,  0.05793253,\n",
       "         -0.12160147, -0.09360275],\n",
       "        ...,\n",
       "        [-0.04601681, -0.11147904,  0.02688688, ...,  0.01715656,\n",
       "         -0.16136546,  0.02237228],\n",
       "        [-0.00032833,  0.06904083, -0.02302837, ...,  0.05102147,\n",
       "          0.03126967,  0.08468917],\n",
       "        [-0.12063925, -0.10051076,  0.16752535, ..., -0.13416454,\n",
       "         -0.11559565, -0.09306905]], dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder/mlp_1/dense_12/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder/mlp_1/dense_13/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.11751008, -0.10675915,  0.16295758, ..., -0.0048849 ,\n",
       "          0.10363197,  0.08136201],\n",
       "        [ 0.0818195 ,  0.07082914, -0.06368215, ...,  0.06165397,\n",
       "         -0.15268016,  0.03727806],\n",
       "        [ 0.045954  , -0.12878314,  0.0454931 , ...,  0.16713569,\n",
       "         -0.07265839,  0.11325756],\n",
       "        ...,\n",
       "        [ 0.15748003, -0.13562912, -0.09616084, ..., -0.08900704,\n",
       "         -0.07938647, -0.032721  ],\n",
       "        [ 0.16422594, -0.16006194, -0.10214597, ...,  0.17284563,\n",
       "          0.11093521,  0.01877442],\n",
       "        [ 0.07877931, -0.10531572, -0.05235576, ...,  0.15052453,\n",
       "          0.0043463 ,  0.09553382]], dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder/mlp_1/dense_13/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (32,32,3)\n",
    "PATCH_SIZE = 8\n",
    "PATCH_NUM = 4*4\n",
    "\n",
    "PROJECTION_DIM = 100\n",
    "HIDDEN_DIM = 50\n",
    "\n",
    "TRANSFORMER_LAYERS = 1\n",
    "TRANSFORMER_HEADS = 2\n",
    "TRANSFORMER_DROPOUT = 0\n",
    "\n",
    "CLASS_NUM=100\n",
    "\n",
    "EPOCHS =10\n",
    "LEARNING_RATE = 0.03\n",
    "BATCH_SIZE = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional version model\n",
    "\n",
    "def ViT():\n",
    "    inputs = tf.keras.layers.Input(shape=INPUT_SHAPE)\n",
    "    patches = Patches(patch_size=PATCH_SIZE)(inputs)\n",
    "    print(patches.shape)\n",
    "    reshaped_patches = tf.reshape(patches, [-1,PATCH_NUM, patches.shape[-1]])\n",
    "    print(reshaped_patches.shape)\n",
    "    embedded_patches = PatchEmbedding(projection_dim=PROJECTION_DIM)(reshaped_patches)\n",
    "\n",
    "    for _ in range(TRANSFORMER_LAYERS):\n",
    "        embedded_patches = TransformerEncoder(TRANSFORMER_HEADS, HIDDEN_DIM, PROJECTION_DIM, dropout=TRANSFORMER_DROPOUT)(embedded_patches) \n",
    "        # shape변화 없음 (batch, patch수+1, projection_dim)   \n",
    "\n",
    "    class_token = embedded_patches[:,0,:] #(batch, 1, projection_dim)\n",
    "    # print(class_token.shape)\n",
    "    outputs = tf.keras.layers.Dense(CLASS_NUM)(class_token)\n",
    "\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4, 4, 192)\n",
      "(None, 16, 192)\n",
      "class token: (1, 1, 100)\n",
      "y1 shape: (None, 16, 100)\n",
      "input batch size: None\n",
      "class token need broadcast to batch axis\n",
      "type of class token: <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
      "class token: (256, 1, 100)\n",
      "number of patches after add dummy class patch: (256, 17, 100)\n",
      "y1: (256, 17, 100)\n"
     ]
    }
   ],
   "source": [
    "vision_transformer = ViT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_transformer.build(input_shape=(BATCH_SIZE,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'patch_embedding_23/dense_46/kernel:0' shape=(192, 100) dtype=float32, numpy=\n",
       " array([[-0.02888576, -0.01962403, -0.06711025, ...,  0.01903354,\n",
       "          0.05218753,  0.01535675],\n",
       "        [ 0.03745648,  0.06046556,  0.10148868, ...,  0.13890259,\n",
       "          0.08158727, -0.13207778],\n",
       "        [-0.08929653,  0.13263933,  0.09741402, ...,  0.10726754,\n",
       "         -0.07365435,  0.08052213],\n",
       "        ...,\n",
       "        [-0.13814443, -0.0285105 , -0.05893788, ...,  0.12152793,\n",
       "          0.13371743,  0.02527665],\n",
       "        [ 0.12740706, -0.01399718,  0.07934046, ..., -0.1234666 ,\n",
       "         -0.08427311,  0.10695146],\n",
       "        [ 0.02495119,  0.07661723,  0.11465655, ...,  0.0265355 ,\n",
       "         -0.09704757, -0.12146619]], dtype=float32)>,\n",
       " <tf.Variable 'patch_embedding_23/dense_46/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'patch_embedding_23/embedding/embeddings:0' shape=(16, 100) dtype=float32, numpy=\n",
       " array([[-0.02156618,  0.01706492, -0.03253373, ...,  0.03188967,\n",
       "         -0.03806344, -0.04974811],\n",
       "        [ 0.0412981 ,  0.03422853,  0.01304934, ...,  0.04426995,\n",
       "          0.00392129, -0.00255145],\n",
       "        [ 0.04858693, -0.01956199, -0.01018357, ..., -0.03308829,\n",
       "          0.01692294, -0.01713613],\n",
       "        ...,\n",
       "        [ 0.00606623, -0.01246504,  0.04963175, ..., -0.03170432,\n",
       "         -0.03912346,  0.01023436],\n",
       "        [-0.02194283, -0.02012334, -0.01074988, ..., -0.01696138,\n",
       "          0.01954093, -0.02945413],\n",
       "        [-0.01673891,  0.0293939 ,  0.04683829, ...,  0.02383466,\n",
       "          0.00568372,  0.01594372]], dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder_7/layer_normalization_9/gamma:0' shape=(100,) dtype=float32, numpy=\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder_7/layer_normalization_9/beta:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder_7/multi_head_attention/query/kernel:0' shape=(100, 2, 50) dtype=float32, numpy=\n",
       " array([[[-1.57100707e-02,  3.36684659e-03, -9.48798843e-03, ...,\n",
       "          -9.30036604e-03,  2.85032839e-02, -1.85309220e-02],\n",
       "         [-9.26349312e-03, -1.87655482e-02, -1.67055037e-02, ...,\n",
       "           2.69257016e-02, -5.48379123e-03, -3.27351727e-02]],\n",
       " \n",
       "        [[-6.18492626e-03, -8.30456987e-03, -2.67490298e-02, ...,\n",
       "          -1.70175470e-02, -3.12221628e-02, -1.12471096e-02],\n",
       "         [-2.43646819e-02,  2.80447192e-02,  1.06726214e-02, ...,\n",
       "           7.96767324e-03,  1.31577738e-02,  1.36531889e-05]],\n",
       " \n",
       "        [[ 9.80273634e-03, -1.59457196e-02,  7.55807385e-03, ...,\n",
       "          -3.31630670e-02,  1.48288943e-02, -7.28379562e-03],\n",
       "         [ 2.59683244e-02, -7.95399398e-03,  1.22341290e-02, ...,\n",
       "          -7.23415054e-03, -5.17492555e-03,  2.98070274e-02]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3.04147191e-02, -1.18455365e-02, -1.96798481e-02, ...,\n",
       "          -3.29656713e-03,  9.29715112e-03,  1.50231011e-02],\n",
       "         [-1.62803810e-02,  2.64332443e-02,  2.54155807e-02, ...,\n",
       "           2.40360275e-02,  2.74895169e-02, -2.62386017e-02]],\n",
       " \n",
       "        [[-8.76344740e-03, -2.30787992e-02,  1.12440959e-02, ...,\n",
       "          -2.12777406e-03, -2.09982656e-02,  1.80075839e-02],\n",
       "         [-1.12693086e-02, -1.60156339e-02, -5.54752909e-03, ...,\n",
       "          -8.18016566e-03,  3.09070386e-02, -1.44210700e-02]],\n",
       " \n",
       "        [[ 3.25143300e-02,  1.14013068e-02,  2.61817724e-02, ...,\n",
       "          -6.87644072e-03,  2.70480886e-02,  9.89130139e-03],\n",
       "         [-2.73013264e-02,  1.34836063e-02, -9.77260806e-03, ...,\n",
       "           1.80997737e-02,  2.97263004e-02, -6.60031661e-03]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder_7/multi_head_attention/key/kernel:0' shape=(100, 2, 50) dtype=float32, numpy=\n",
       " array([[[ 0.00290133,  0.00813135,  0.0189385 , ..., -0.00393977,\n",
       "          -0.00153231,  0.02482534],\n",
       "         [ 0.00314195,  0.00457779,  0.01243222, ...,  0.00939098,\n",
       "          -0.02206527,  0.00553291]],\n",
       " \n",
       "        [[ 0.00194823,  0.0145889 , -0.02470619, ..., -0.00049416,\n",
       "          -0.00726804, -0.03120265],\n",
       "         [-0.01146943, -0.03377107, -0.01707961, ..., -0.00928755,\n",
       "           0.00911442, -0.02188432]],\n",
       " \n",
       "        [[-0.02563092, -0.03238453,  0.02015629, ...,  0.02329026,\n",
       "           0.02365142,  0.0338735 ],\n",
       "         [ 0.02535504,  0.0030439 , -0.00217437, ...,  0.00681642,\n",
       "           0.01443462, -0.01326113]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.00104202,  0.00653414, -0.0039989 , ..., -0.02168119,\n",
       "           0.02449951, -0.00554909],\n",
       "         [-0.02065728,  0.00436664, -0.03084842, ...,  0.00989862,\n",
       "          -0.01788311, -0.02293312]],\n",
       " \n",
       "        [[-0.02533498,  0.03062681, -0.01534273, ..., -0.02987233,\n",
       "          -0.02109672,  0.03045104],\n",
       "         [ 0.03084473, -0.00293671, -0.02367784, ..., -0.00067342,\n",
       "           0.02733792,  0.00496047]],\n",
       " \n",
       "        [[-0.0279591 , -0.0121578 , -0.00208658, ...,  0.01268936,\n",
       "          -0.02631202, -0.03368568],\n",
       "         [-0.01278288,  0.00938815, -0.01548741, ..., -0.01922315,\n",
       "           0.02194773,  0.01660041]]], dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder_7/multi_head_attention/value/kernel:0' shape=(100, 2, 50) dtype=float32, numpy=\n",
       " array([[[ 0.01647237, -0.00815645,  0.00986237, ...,  0.02162923,\n",
       "          -0.01978962, -0.02875398],\n",
       "         [-0.02574902,  0.01344923, -0.01003816, ..., -0.0316726 ,\n",
       "          -0.01173932,  0.00881115]],\n",
       " \n",
       "        [[-0.01151722, -0.01329886, -0.01239307, ...,  0.00339177,\n",
       "          -0.02702907, -0.00324972],\n",
       "         [ 0.02795552, -0.02053626, -0.03388725, ...,  0.01586755,\n",
       "          -0.0144182 , -0.02861549]],\n",
       " \n",
       "        [[ 0.01849749, -0.00350226,  0.0040469 , ...,  0.01294198,\n",
       "          -0.0002659 ,  0.01834344],\n",
       "         [ 0.02908797,  0.00779215, -0.00947253, ...,  0.0041296 ,\n",
       "          -0.02604256, -0.0076111 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.01802121, -0.01479277, -0.01191745, ..., -0.02660035,\n",
       "           0.00847916,  0.02461277],\n",
       "         [-0.0295283 ,  0.00673943, -0.00019383, ...,  0.00405275,\n",
       "          -0.01348912,  0.02878972]],\n",
       " \n",
       "        [[ 0.01355275,  0.01024252, -0.00020682, ..., -0.02071553,\n",
       "          -0.03054422, -0.02942185],\n",
       "         [ 0.02924682, -0.00690086,  0.00581602, ..., -0.0037383 ,\n",
       "          -0.01368456, -0.01971956]],\n",
       " \n",
       "        [[-0.02163921,  0.02223675, -0.00757293, ...,  0.00460359,\n",
       "           0.0067495 , -0.03031222],\n",
       "         [-0.008056  , -0.00255537,  0.03319353, ..., -0.00542006,\n",
       "          -0.02817403, -0.00042124]]], dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder_7/multi_head_attention/attention_output/kernel:0' shape=(2, 50, 100) dtype=float32, numpy=\n",
       " array([[[-0.13526852,  0.05225673,  0.12750848, ..., -0.02735563,\n",
       "           0.11298434, -0.10920238],\n",
       "         [-0.12102108,  0.13572438,  0.02912526, ...,  0.09432884,\n",
       "          -0.02719955,  0.01913232],\n",
       "         [ 0.00377876,  0.10184456, -0.07091909, ..., -0.13994646,\n",
       "           0.0852177 , -0.0895773 ],\n",
       "         ...,\n",
       "         [ 0.01416387, -0.06683452,  0.02945513, ..., -0.09236647,\n",
       "           0.09316987,  0.08480948],\n",
       "         [ 0.10360117,  0.1017164 , -0.01779855, ..., -0.13530315,\n",
       "          -0.0692321 ,  0.12585278],\n",
       "         [-0.10388848, -0.02062967,  0.02311006, ..., -0.06769522,\n",
       "           0.02453968,  0.00033036]],\n",
       " \n",
       "        [[-0.04879618,  0.05282262, -0.10154238, ...,  0.05157509,\n",
       "           0.04022661,  0.10470572],\n",
       "         [ 0.09976874, -0.0244386 , -0.1342531 , ...,  0.13180639,\n",
       "           0.01712245, -0.0557587 ],\n",
       "         [ 0.13579999, -0.09127015,  0.01611413, ...,  0.08902386,\n",
       "          -0.13106395, -0.01743709],\n",
       "         ...,\n",
       "         [-0.08132377, -0.04845516, -0.10328385, ..., -0.09821339,\n",
       "           0.08231071, -0.01387949],\n",
       "         [ 0.1287796 , -0.12228163,  0.13488407, ..., -0.09667324,\n",
       "           0.03932054,  0.1228203 ],\n",
       "         [-0.04388573, -0.08176668,  0.13041379, ...,  0.09509745,\n",
       "           0.01458757, -0.0507935 ]]], dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder_7/mlp/dense/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.13319185,  0.06423639,  0.01171894, ..., -0.10814164,\n",
       "          0.1149542 , -0.11121842],\n",
       "        [-0.07553069,  0.07332395,  0.00963783, ..., -0.0657973 ,\n",
       "          0.16113463, -0.14415894],\n",
       "        [-0.03683199, -0.01830828, -0.00586224, ...,  0.09002638,\n",
       "         -0.06566446,  0.05900981],\n",
       "        ...,\n",
       "        [ 0.02350467,  0.07495953, -0.08262361, ...,  0.0810594 ,\n",
       "          0.15807667,  0.15264308],\n",
       "        [-0.13666087, -0.04031955, -0.00772531, ...,  0.13301012,\n",
       "          0.16721126,  0.15801138],\n",
       "        [ 0.0021524 ,  0.09711152,  0.09150875, ...,  0.155245  ,\n",
       "         -0.03282346, -0.01470633]], dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder_7/mlp/dense/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder_7/mlp/dense_1/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[ 0.01392396,  0.12840778, -0.07833637, ...,  0.14806023,\n",
       "         -0.11663996,  0.12991115],\n",
       "        [-0.05241767,  0.1118395 ,  0.0065477 , ..., -0.04446027,\n",
       "          0.12564412, -0.1326767 ],\n",
       "        [-0.08694831,  0.11671132, -0.10685467, ..., -0.01595238,\n",
       "          0.08772573, -0.04936392],\n",
       "        ...,\n",
       "        [ 0.13043562,  0.14610079,  0.0563373 , ...,  0.01567096,\n",
       "         -0.00783789, -0.12043636],\n",
       "        [-0.03480963, -0.15333068, -0.05452199, ...,  0.1731041 ,\n",
       "         -0.0091223 ,  0.04241408],\n",
       "        [-0.03630556, -0.16559225, -0.06124606, ...,  0.05050941,\n",
       "         -0.10603087, -0.04418792]], dtype=float32)>,\n",
       " <tf.Variable 'transformer_encoder_7/mlp/dense_1/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_47/kernel:0' shape=(100, 100) dtype=float32, numpy=\n",
       " array([[-0.14477219, -0.15860187,  0.06379031, ..., -0.00218931,\n",
       "          0.09387717, -0.12774199],\n",
       "        [ 0.00153218, -0.0616717 , -0.08269601, ...,  0.03313074,\n",
       "          0.14998299, -0.04648601],\n",
       "        [ 0.13837019, -0.11895514,  0.09806389, ...,  0.02822286,\n",
       "          0.16152433, -0.13867696],\n",
       "        ...,\n",
       "        [ 0.09165895,  0.08609334, -0.17254984, ...,  0.07765278,\n",
       "          0.14566103,  0.17137063],\n",
       "        [ 0.10261041,  0.04143558,  0.01440777, ...,  0.14621755,\n",
       "         -0.04252376, -0.04192431],\n",
       "        [-0.06523568,  0.08987167,  0.14799842, ..., -0.08026854,\n",
       "          0.08321455, -0.14663047]], dtype=float32)>,\n",
       " <tf.Variable 'dense_47/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE variable 개수가 16이어야 될거 같은데?\n",
    "print(len(vision_transformer.variables))\n",
    "vision_transformer.variables\n",
    "\n",
    "# 2 : position embedding\n",
    "# 1 : projection \n",
    "# 1 : learnable class token\n",
    "# 2*layer : transformer layer norm (gamma,beta)\n",
    "# 2*2*layer : transformer MLP\n",
    "# 4*layer : transformer MSA (key,query,value,output)\n",
    "# 2 : dense for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(tf.keras.Model):\n",
    "    def __init__(self, patch_size, projection_dim, hidden_dim, transformer_layer_num, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.patch_size = patch_size\n",
    "        self.projection_dim = projection_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.transformer_layer_num = transformer_layer_num\n",
    "\n",
    "        self.make_patch = Patches(patch_size)\n",
    "        self.patch_embedding = PatchEmbedding(projection_dim=100)\n",
    "        self.transformer_layer = TransformerEncoder\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # image to patches and reshape for projection\n",
    "\n",
    "        # projection and position embedding\n",
    "\n",
    "        # transformer layer\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
    "vision_transformer.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = [\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.SparseTopKCategoricalAccuracy(5, name='top-5-accuracy')\n",
    "    ],    \n",
    ") # 정답이 one_hot으로 되어있다는 뜻\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "class token: (256, 1, 100)\n",
      "y1 shape: (None, 16, 100)\n",
      "input batch size: None\n",
      "class token need broadcast to batch axis\n",
      "type of class token: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "class token: (256, 1, 100)\n",
      "number of patches after add dummy class patch: (256, 17, 100)\n",
      "y1: (256, 17, 100)\n",
      "class token: (256, 1, 100)\n",
      "y1 shape: (None, 16, 100)\n",
      "input batch size: None\n",
      "class token need broadcast to batch axis\n",
      "type of class token: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "class token: (256, 1, 100)\n",
      "number of patches after add dummy class patch: (256, 17, 100)\n",
      "y1: (256, 17, 100)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<tf.Tensor 'model_6/patch_embedding_23/BroadcastTo:0' shape=(256, 1, 100) dtype=float32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.\nPlease see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\n\n<tf.Tensor 'model_6/patch_embedding_23/BroadcastTo:0' shape=(256, 1, 100) dtype=float32> was defined here:\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/traitlets/config/application.py\", line 965, in launch_instance\n      app.start()\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_532391/3003937714.py\", line 1, in <cell line: 1>\n      history = vision_transformer.fit(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 915, in __call__\n      result = self._call(*args, **kwds)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 963, in _call\n      self._initialize(args, kwds, add_initializers_to=initializers)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 785, in _initialize\n      self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 2983, in _get_concrete_function_internal_garbage_collected\n      graph_function, _ = self._maybe_define_function(args, kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3292, in _maybe_define_function\n      graph_function = self._create_graph_function(args, kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3130, in _create_graph_function\n      func_graph_module.func_graph_from_py_func(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1161, in func_graph_from_py_func\n      func_outputs = python_func(*func_args, **func_kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 677, in wrapped_fn\n      out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1136, in autograph_handler\n      return autograph.converted_call(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1312, in run\n      return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 2888, in call_for_each_replica\n      return self._call_for_each_replica(fn, args, kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 3689, in _call_for_each_replica\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_532391/3443066435.py\", line 31, in call\n      if self.batch_size != 1:# 여기가 None인 경우가 있어 의도대로 처리가 안될수도\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1321, in if_stmt\n      _py_if_stmt(cond, body, orelse)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1374, in _py_if_stmt\n      return body() if cond else orelse()\n    File \"/tmp/ipykernel_532391/3443066435.py\", line 35, in call\n      self.class_token = tf.broadcast_to(self.class_token, shape=[BATCH_SIZE,1,self.projection_dim])\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 876, in broadcast_to\n      _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 740, in _apply_op_helper\n      op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 693, in _create_op_internal\n      return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3776, in _create_op_internal\n      ret = Operation(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n      self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n\nThe tensor <tf.Tensor 'model_6/patch_embedding_23/BroadcastTo:0' shape=(256, 1, 100) dtype=float32> cannot be accessed from here, because it was defined in FuncGraph(name=train_function, id=139779717021216), which is out of scope.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb 셀 74\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb#Y155sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m vision_transformer\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb#Y155sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     x\u001b[39m=\u001b[39;49mx_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb#Y155sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     y\u001b[39m=\u001b[39;49my_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb#Y155sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     batch_size \u001b[39m=\u001b[39;49m BATCH_SIZE,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb#Y155sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m EPOCHS\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cvnar1/Desktop/model/ViT/ViT_layer.ipynb#Y155sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: <tf.Tensor 'model_6/patch_embedding_23/BroadcastTo:0' shape=(256, 1, 100) dtype=float32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.\nPlease see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.\n\n<tf.Tensor 'model_6/patch_embedding_23/BroadcastTo:0' shape=(256, 1, 100) dtype=float32> was defined here:\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/traitlets/config/application.py\", line 965, in launch_instance\n      app.start()\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/cvnar1/.local/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_532391/3003937714.py\", line 1, in <cell line: 1>\n      history = vision_transformer.fit(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 915, in __call__\n      result = self._call(*args, **kwds)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 963, in _call\n      self._initialize(args, kwds, add_initializers_to=initializers)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 785, in _initialize\n      self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 2983, in _get_concrete_function_internal_garbage_collected\n      graph_function, _ = self._maybe_define_function(args, kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3292, in _maybe_define_function\n      graph_function = self._create_graph_function(args, kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3130, in _create_graph_function\n      func_graph_module.func_graph_from_py_func(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1161, in func_graph_from_py_func\n      func_outputs = python_func(*func_args, **func_kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 677, in wrapped_fn\n      out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1136, in autograph_handler\n      return autograph.converted_call(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1312, in run\n      return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 2888, in call_for_each_replica\n      return self._call_for_each_replica(fn, args, kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 3689, in _call_for_each_replica\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/tmp/ipykernel_532391/3443066435.py\", line 31, in call\n      if self.batch_size != 1:# 여기가 None인 경우가 있어 의도대로 처리가 안될수도\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1321, in if_stmt\n      _py_if_stmt(cond, body, orelse)\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1374, in _py_if_stmt\n      return body() if cond else orelse()\n    File \"/tmp/ipykernel_532391/3443066435.py\", line 35, in call\n      self.class_token = tf.broadcast_to(self.class_token, shape=[BATCH_SIZE,1,self.projection_dim])\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 876, in broadcast_to\n      _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 740, in _apply_op_helper\n      op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 693, in _create_op_internal\n      return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 3776, in _create_op_internal\n      ret = Operation(\n    File \"/home/cvnar1/anaconda3/envs/tensorflow2.8/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 2175, in __init__\n      self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n\nThe tensor <tf.Tensor 'model_6/patch_embedding_23/BroadcastTo:0' shape=(256, 1, 100) dtype=float32> cannot be accessed from here, because it was defined in FuncGraph(name=train_function, id=139779717021216), which is out of scope."
     ]
    }
   ],
   "source": [
    "history = vision_transformer.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs = EPOCHS\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensorflow2.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05a0b0d24b486f762a660818e658a0e3bfd75854f8c75d6662c85db23d29aee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
